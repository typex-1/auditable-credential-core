{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import getopt\n",
    "from blindIssuing_dl_version2 import initialization, tracer_choose_keypair, Issuer, User, verify\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1024\n",
    "round = 10\n",
    "m = b'my msg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issuing Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_test(L, round, time_recoder=[], flag=1):    \n",
    "    params = initialization(L)\n",
    "    traceKeypair = tracer_choose_keypair(params)\n",
    "    tkey = traceKeypair.yt\n",
    "    xt = traceKeypair.xt\n",
    "    total = 0\n",
    "    for x in range(round):\n",
    "        start = time.time()\n",
    "        issuer = Issuer(params,tkey)\n",
    "        # get the hash \n",
    "        issuer.start()\n",
    "\n",
    "        user = User(params, issuer.IssuerKeypair.y,tkey)    \n",
    "        user.start()\n",
    "\n",
    "        zu, xi = user.protocol_one()    \n",
    "        z1, a, b1, b2 = issuer.protocol_two(zu,xi)    \n",
    "        e = user.protocol_three(z1, a, b1, b2, m)    \n",
    "        r, c, s1, s2, d = issuer.protocol_four(e)    \n",
    "        roi, pi, sigma1, sigma2, delta = user.protocol_five(r, c, s1, s2, d)\n",
    "\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        if not flag: time_recoder.append(runtime)\n",
    "        msg = '{func} takes {time} second to complete'\n",
    "        total = total + runtime\n",
    "        if flag: print(msg.format(func = '[Credential Issuing]', time = runtime))\n",
    "    if flag: print(\"The average time is {time} second for {rounds} tests\".format(time=total/round, rounds=round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Credential Issuing] takes 0.006581783294677734 second to complete\n",
      "[Credential Issuing] takes 0.006831645965576172 second to complete\n",
      "[Credential Issuing] takes 0.006582736968994141 second to complete\n",
      "[Credential Issuing] takes 0.006568193435668945 second to complete\n",
      "[Credential Issuing] takes 0.006573200225830078 second to complete\n",
      "[Credential Issuing] takes 0.00668025016784668 second to complete\n",
      "[Credential Issuing] takes 0.006635904312133789 second to complete\n",
      "[Credential Issuing] takes 0.006600141525268555 second to complete\n",
      "[Credential Issuing] takes 0.006631135940551758 second to complete\n",
      "[Credential Issuing] takes 0.006545066833496094 second to complete\n",
      "The average time is 0.006623005867004395 second for 10 tests\n"
     ]
    }
   ],
   "source": [
    "issue_test(L, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_test(L, round, time_recoder=[], flag=1):\n",
    "    total = 0\n",
    "    for x in range(round):\n",
    "        start = time.time()\n",
    "        params = initialization(L)\n",
    "        traceKeypair = tracer_choose_keypair(params)\n",
    "        tkey = traceKeypair.yt\n",
    "        xt = traceKeypair.xt\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        if not flag: time_recoder.append(runtime)\n",
    "        msg = '{func} takes {time} second to complete'\n",
    "        total = total + runtime\n",
    "        if flag: print(msg.format(func = '[Parameter Generation]', time = runtime))\n",
    "    if flag: print(\"The average time is {time} second for {rounds} tests\".format(time=total/round, rounds=round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter Generation] takes 1.2227978706359863 second to complete\n",
      "[Parameter Generation] takes 0.15206646919250488 second to complete\n",
      "[Parameter Generation] takes 1.6951746940612793 second to complete\n",
      "[Parameter Generation] takes 1.086684226989746 second to complete\n",
      "[Parameter Generation] takes 1.9909718036651611 second to complete\n",
      "[Parameter Generation] takes 3.2271177768707275 second to complete\n",
      "[Parameter Generation] takes 3.7894954681396484 second to complete\n",
      "[Parameter Generation] takes 3.059931755065918 second to complete\n",
      "[Parameter Generation] takes 8.676132917404175 second to complete\n",
      "[Parameter Generation] takes 2.6000592708587646 second to complete\n",
      "The average time is 2.7500432252883913 second for 10 tests\n"
     ]
    }
   ],
   "source": [
    "parameter_test(L, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifying_test(L, round, time_recoder=[], flag=1):\n",
    "    total = 0\n",
    "    params = initialization(L)\n",
    "    traceKeypair = tracer_choose_keypair(params)\n",
    "    tkey = traceKeypair.yt\n",
    "    xt = traceKeypair.xt\n",
    "    \n",
    "    for x in range(round):\n",
    "        issuer = Issuer(params, tkey)\n",
    "        issuer.start()\n",
    "\n",
    "        user = User(params, issuer.IssuerKeypair.y,tkey)    \n",
    "        user.start()\n",
    "\n",
    "        zu, xi = user.protocol_one()    \n",
    "        z1, a, b1, b2 = issuer.protocol_two(zu,xi)    \n",
    "        e = user.protocol_three(z1, a, b1, b2, m)    \n",
    "        r, c, s1, s2, d = issuer.protocol_four(e)    \n",
    "        roi, pi, sigma1, sigma2, delta = user.protocol_five(r, c, s1, s2, d)\n",
    "        \n",
    "        start = time.time()\n",
    "        verify(roi, pi, sigma1, sigma2, delta, params, m, user.y, user.zeta1,user.zeta2, user.z)\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        if not flag: time_recoder.append(runtime)\n",
    "        msg = '{func} takes {time} second to complete'\n",
    "        total = total + runtime\n",
    "        if flag: print(msg.format(func = '[Credential Verifying]', time = runtime))\n",
    "    if flag:print(\"The average time is {time} second for {rounds} tests\".format(time=total/round, rounds=round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Credential Verifying] takes 0.0030126571655273438 second to complete\n",
      "[Credential Verifying] takes 0.0031728744506835938 second to complete\n",
      "[Credential Verifying] takes 0.003055095672607422 second to complete\n",
      "[Credential Verifying] takes 0.003041505813598633 second to complete\n",
      "[Credential Verifying] takes 0.0030112266540527344 second to complete\n",
      "[Credential Verifying] takes 0.003015279769897461 second to complete\n",
      "[Credential Verifying] takes 0.003070354461669922 second to complete\n",
      "[Credential Verifying] takes 0.003075122833251953 second to complete\n",
      "[Credential Verifying] takes 0.003068685531616211 second to complete\n",
      "[Credential Verifying] takes 0.0030694007873535156 second to complete\n",
      "The average time is 0.0030592203140258787 second for 10 tests\n"
     ]
    }
   ],
   "source": [
    "verifying_test(L, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 1000\n",
    "L = 1024\n",
    "issue_time = []\n",
    "parameter_time = []\n",
    "verify_time = []\n",
    "identify = ['Average Time']\n",
    "identify.extend(['#'+str(x) for x in range(1,times + 1)])\n",
    "issue_test(L, times, issue_time, 0)\n",
    "parameter_test(L, times, parameter_time, 0)\n",
    "verifying_test(L, times, verify_time, 0)\n",
    "avg1 = sum(issue_time)/times\n",
    "avg2 = sum(parameter_time)/times\n",
    "avg3 = sum(verify_time)/times\n",
    "issue_time.insert(0, avg1)\n",
    "parameter_time.insert(0, avg2)\n",
    "verify_time.insert(0, avg3)\n",
    "dataframe = pd.DataFrame({'Rounds [TEST DATE: ' + time.strftime('%Y-%m-%d %H:%M',time.localtime(time.time())) + ']':identify, 'Issuing Time':issue_time,'Parameter Time': parameter_time, 'Verifying Time': verify_time})\n",
    "dataframe.to_csv('./DL_1024_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 1000\n",
    "L = 256\n",
    "issue_time = []\n",
    "parameter_time = []\n",
    "verify_time = []\n",
    "identify = ['Average Time']\n",
    "identify.extend(['#'+str(x) for x in range(1,times + 1)])\n",
    "issue_test(L, times, issue_time, 0)\n",
    "parameter_test(L, times, parameter_time, 0)\n",
    "verifying_test(L, times, verify_time, 0)\n",
    "avg1 = sum(issue_time)/times\n",
    "avg2 = sum(parameter_time)/times\n",
    "avg3 = sum(verify_time)/times\n",
    "issue_time.insert(0, avg1)\n",
    "parameter_time.insert(0, avg2)\n",
    "verify_time.insert(0, avg3)\n",
    "dataframe = pd.DataFrame({'Rounds [TEST DATE: ' + time.strftime('%Y-%m-%d %H:%M',time.localtime(time.time())) + ']':identify, 'Issuing Time':issue_time,'Parameter Time': parameter_time, 'Verifying Time': verify_time})\n",
    "dataframe.to_csv('./DL_256_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
