{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from charm.toolbox.eccurve import secp256k1, secp192k1, secp160k1\n",
    "from blindIssuing_ecc import initialization, tracer_choose_keypair, Issuer, User, verify\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = secp192k1\n",
    "round = 10\n",
    "m = b'my msg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issuing Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_test(L, round, time_recoder=[], flag=1):\n",
    "    params = initialization(L)\n",
    "    traceKeypair = tracer_choose_keypair(params)\n",
    "    tkey = traceKeypair.yt\n",
    "    xt = traceKeypair.xt\n",
    "    total = 0\n",
    "    for x in range(round):\n",
    "        start = time.time()\n",
    "        issuer = Issuer(params,tkey)\n",
    "        # get the hash \n",
    "        issuer.start()\n",
    "\n",
    "        user = User(params, issuer.IssuerKeypair.y,tkey)    \n",
    "        user.start()\n",
    "\n",
    "        zu, xi = user.protocol_one()\n",
    "        z1, a, b1, b2 = issuer.protocol_two(zu,xi)    \n",
    "        e = user.protocol_three(z1, a, b1, b2, m)    \n",
    "        r, c, s1, s2, d = issuer.protocol_four(e)    \n",
    "        roi, pi, sigma1, sigma2, delta = user.protocol_five(r, c, s1, s2, d)\n",
    "\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        time_recoder.append(runtime)\n",
    "        msg = '{func} takes {time} second to complete'\n",
    "        total = total + runtime\n",
    "        if flag :print(msg.format(func = '[Credential Issuing]', time = runtime))\n",
    "    if flag :print(\"The average time is {time} second for {rounds} tests\".format(time=total/round, rounds=round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Credential Issuing] takes 0.004769086837768555 second to complete\n",
      "[Credential Issuing] takes 0.0046539306640625 second to complete\n",
      "[Credential Issuing] takes 0.004614591598510742 second to complete\n",
      "[Credential Issuing] takes 0.004714012145996094 second to complete\n",
      "[Credential Issuing] takes 0.004824399948120117 second to complete\n",
      "[Credential Issuing] takes 0.004595279693603516 second to complete\n",
      "[Credential Issuing] takes 0.0046825408935546875 second to complete\n",
      "[Credential Issuing] takes 0.004731416702270508 second to complete\n",
      "[Credential Issuing] takes 0.004714488983154297 second to complete\n",
      "[Credential Issuing] takes 0.004746198654174805 second to complete\n",
      "The average time is 0.004704594612121582 second for 10 tests\n"
     ]
    }
   ],
   "source": [
    "issue_test(L, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_test(L, round, time_recoder=[], flag=1):\n",
    "    total = 0\n",
    "    for x in range(round):\n",
    "        start = time.time()\n",
    "        params = initialization(L)\n",
    "        traceKeypair = tracer_choose_keypair(params)\n",
    "        tkey = traceKeypair.yt\n",
    "        xt = traceKeypair.xt\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        if not flag: time_recoder.append(runtime)\n",
    "        msg = '{func} takes {time} second to complete'\n",
    "        total = total + runtime\n",
    "        if flag: print(msg.format(func = '[Parameter Generation]', time = runtime))\n",
    "    if flag: print(\"The average time is {time} second for {rounds} tests\".format(time=total/round, rounds=round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter Generation] takes 0.0006766319274902344 second to complete\n",
      "[Parameter Generation] takes 0.0005941390991210938 second to complete\n",
      "[Parameter Generation] takes 0.0005698204040527344 second to complete\n",
      "[Parameter Generation] takes 0.0005195140838623047 second to complete\n",
      "[Parameter Generation] takes 0.0005152225494384766 second to complete\n",
      "[Parameter Generation] takes 0.0005269050598144531 second to complete\n",
      "[Parameter Generation] takes 0.0005404949188232422 second to complete\n",
      "[Parameter Generation] takes 0.0005435943603515625 second to complete\n",
      "[Parameter Generation] takes 0.0005245208740234375 second to complete\n",
      "[Parameter Generation] takes 0.0005371570587158203 second to complete\n",
      "The average time is 0.0005548000335693359 second for 10 tests\n"
     ]
    }
   ],
   "source": [
    "parameter_test(L, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifying_test(L, round, time_recoder=[], flag=1):\n",
    "    total = 0\n",
    "    params = initialization(L)\n",
    "    traceKeypair = tracer_choose_keypair(params)\n",
    "    tkey = traceKeypair.yt\n",
    "    xt = traceKeypair.xt\n",
    "    \n",
    "    for x in range(round):\n",
    "        issuer = Issuer(params, tkey)\n",
    "        issuer.start()\n",
    "\n",
    "        user = User(params, issuer.IssuerKeypair.y,tkey)    \n",
    "        user.start()\n",
    "\n",
    "        zu, xi = user.protocol_one()    \n",
    "        z1, a, b1, b2 = issuer.protocol_two(zu,xi)    \n",
    "        e = user.protocol_three(z1, a, b1, b2, m)    \n",
    "        r, c, s1, s2, d = issuer.protocol_four(e)    \n",
    "        roi, pi, sigma1, sigma2, delta = user.protocol_five(r, c, s1, s2, d)\n",
    "        \n",
    "        start = time.time()\n",
    "        verify(roi, pi, sigma1, sigma2, delta, params, m, user.y, user.zeta1,user.zeta2, user.z)\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        if not flag: time_recoder.append(runtime)\n",
    "        msg = '{func} takes {time} second to complete'\n",
    "        total = total + runtime\n",
    "        if flag: print(msg.format(func = '[Credential Verifying]', time = runtime))\n",
    "    if flag: print(\"The average time is {time} second for {rounds} tests\".format(time=total/round, rounds=round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Credential Verifying] takes 0.0014700889587402344 second to complete\n",
      "[Credential Verifying] takes 0.0015115737915039062 second to complete\n",
      "[Credential Verifying] takes 0.0015730857849121094 second to complete\n",
      "[Credential Verifying] takes 0.0015149116516113281 second to complete\n",
      "[Credential Verifying] takes 0.001596689224243164 second to complete\n",
      "[Credential Verifying] takes 0.0015096664428710938 second to complete\n",
      "[Credential Verifying] takes 0.0017621517181396484 second to complete\n",
      "[Credential Verifying] takes 0.0015745162963867188 second to complete\n",
      "[Credential Verifying] takes 0.0015840530395507812 second to complete\n",
      "[Credential Verifying] takes 0.0016064643859863281 second to complete\n",
      "The average time is 0.0015703201293945312 second for 10 tests\n"
     ]
    }
   ],
   "source": [
    "verifying_test(L, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 1000\n",
    "issue_time = []\n",
    "parameter_time = []\n",
    "verify_time = []\n",
    "identify = ['Average Time']\n",
    "identify.extend(['#'+str(x) for x in range(1,times + 1)])\n",
    "issue_test(L, times, issue_time, 0)\n",
    "parameter_test(L, times, parameter_time, 0)\n",
    "verifying_test(L, times, verify_time, 0)\n",
    "avg1 = sum(issue_time)/times\n",
    "avg2 = sum(parameter_time)/times\n",
    "avg3 = sum(verify_time)/times\n",
    "issue_time.insert(0, avg1)\n",
    "parameter_time.insert(0, avg2)\n",
    "verify_time.insert(0, avg3)\n",
    "dataframe = pd.DataFrame({'Rounds [TEST DATE: ' + time.strftime('%Y-%m-%d %H:%M',time.localtime(time.time())) + ']':identify, 'Issuing Time':issue_time, 'Parameter Time': parameter_time, 'Verifying Time': verify_time})\n",
    "dataframe.to_csv('./ECC_192_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
