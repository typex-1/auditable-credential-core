{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from charm.toolbox.eccurve import secp256k1, secp192k1, secp160k1\n",
    "from blindIssuing_ecc import initialization, tracer_choose_keypair, Issuer, User, verify\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = secp256k1\n",
    "round = 10\n",
    "m = b'my msg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issuing Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_test(L, round, time_recoder=[], flag=1):\n",
    "    params = initialization(L)\n",
    "    traceKeypair = tracer_choose_keypair(params)\n",
    "    tkey = traceKeypair.yt\n",
    "    xt = traceKeypair.xt\n",
    "    total = 0\n",
    "    for x in range(round):\n",
    "        start = time.time()\n",
    "        issuer = Issuer(params,tkey)\n",
    "        # get the hash \n",
    "        issuer.start()\n",
    "\n",
    "        user = User(params, issuer.IssuerKeypair.y,tkey)    \n",
    "        user.start()\n",
    "\n",
    "        zu, xi = user.protocol_one()\n",
    "        z1, a, b1, b2 = issuer.protocol_two(zu,xi)    \n",
    "        e = user.protocol_three(z1, a, b1, b2, m)    \n",
    "        r, c, s1, s2, d = issuer.protocol_four(e)    \n",
    "        roi, pi, sigma1, sigma2, delta = user.protocol_five(r, c, s1, s2, d)\n",
    "\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        if not flag: time_recoder.append(runtime)\n",
    "        msg = '{func} takes {time} second to complete'\n",
    "        total = total + runtime\n",
    "        if flag: print(msg.format(func = '[Credential Issuing]', time = runtime))\n",
    "    if flag: print(\"The average time is {time} second for {rounds} tests\".format(time=total/round, rounds=round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Credential Issuing] takes 0.007844686508178711 second to complete\n",
      "[Credential Issuing] takes 0.007528066635131836 second to complete\n",
      "[Credential Issuing] takes 0.007661581039428711 second to complete\n",
      "[Credential Issuing] takes 0.007700920104980469 second to complete\n",
      "[Credential Issuing] takes 0.007668972015380859 second to complete\n",
      "[Credential Issuing] takes 0.007695198059082031 second to complete\n",
      "[Credential Issuing] takes 0.007824897766113281 second to complete\n",
      "[Credential Issuing] takes 0.007707834243774414 second to complete\n",
      "[Credential Issuing] takes 0.007971763610839844 second to complete\n",
      "[Credential Issuing] takes 0.007707834243774414 second to complete\n",
      "The average time is 0.007731175422668457 second for 10 tests\n"
     ]
    }
   ],
   "source": [
    "issue_test(L, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_test(L, round, time_recoder=[], flag=1):\n",
    "    total = 0\n",
    "    for x in range(round):\n",
    "        start = time.time()\n",
    "        params = initialization(L)\n",
    "        traceKeypair = tracer_choose_keypair(params)\n",
    "        tkey = traceKeypair.yt\n",
    "        xt = traceKeypair.xt\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        if not flag:time_recoder.append(runtime)\n",
    "        msg = '{func} takes {time} second to complete'\n",
    "        total = total + runtime\n",
    "        if flag: print(msg.format(func = '[Parameter Generation]', time = runtime))\n",
    "    if flag: print(\"The average time is {time} second for {rounds} tests\".format(time=total/round, rounds=round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter Generation] takes 0.0008521080017089844 second to complete\n",
      "[Parameter Generation] takes 0.0008642673492431641 second to complete\n",
      "[Parameter Generation] takes 0.0008549690246582031 second to complete\n",
      "[Parameter Generation] takes 0.0008461475372314453 second to complete\n",
      "[Parameter Generation] takes 0.0008308887481689453 second to complete\n",
      "[Parameter Generation] takes 0.0009164810180664062 second to complete\n",
      "[Parameter Generation] takes 0.0008661746978759766 second to complete\n",
      "[Parameter Generation] takes 0.0008342266082763672 second to complete\n",
      "[Parameter Generation] takes 0.0008628368377685547 second to complete\n",
      "[Parameter Generation] takes 0.0008618831634521484 second to complete\n",
      "The average time is 0.0008589982986450196 second for 10 tests\n"
     ]
    }
   ],
   "source": [
    "parameter_test(L, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifying_test(L, round, time_recoder=[], flag=1):\n",
    "    total = 0\n",
    "    params = initialization(L)\n",
    "    traceKeypair = tracer_choose_keypair(params)\n",
    "    tkey = traceKeypair.yt\n",
    "    xt = traceKeypair.xt\n",
    "    \n",
    "    for x in range(round):\n",
    "        issuer = Issuer(params, tkey)\n",
    "        issuer.start()\n",
    "\n",
    "        user = User(params, issuer.IssuerKeypair.y,tkey)    \n",
    "        user.start()\n",
    "\n",
    "        zu, xi = user.protocol_one()    \n",
    "        z1, a, b1, b2 = issuer.protocol_two(zu,xi)    \n",
    "        e = user.protocol_three(z1, a, b1, b2, m)    \n",
    "        r, c, s1, s2, d = issuer.protocol_four(e)    \n",
    "        roi, pi, sigma1, sigma2, delta = user.protocol_five(r, c, s1, s2, d)\n",
    "        \n",
    "        start = time.time()\n",
    "        verify(roi, pi, sigma1, sigma2, delta, params, m, user.y, user.zeta1,user.zeta2, user.z)\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        if not flag: time_recoder.append(runtime)\n",
    "        msg = '{func} takes {time} second to complete'\n",
    "        total = total + runtime\n",
    "        if flag: print(msg.format(func = '[Credential Verifying]', time = runtime))\n",
    "    if flag: print(\"The average time is {time} second for {rounds} tests\".format(time=total/round, rounds=round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Credential Verifying] takes 0.0024726390838623047 second to complete\n",
      "[Credential Verifying] takes 0.0024449825286865234 second to complete\n",
      "[Credential Verifying] takes 0.002430438995361328 second to complete\n",
      "[Credential Verifying] takes 0.0024261474609375 second to complete\n",
      "[Credential Verifying] takes 0.002432107925415039 second to complete\n",
      "[Credential Verifying] takes 0.002431631088256836 second to complete\n",
      "[Credential Verifying] takes 0.0024340152740478516 second to complete\n",
      "[Credential Verifying] takes 0.002429485321044922 second to complete\n",
      "[Credential Verifying] takes 0.002428293228149414 second to complete\n",
      "[Credential Verifying] takes 0.0024344921112060547 second to complete\n",
      "The average time is 0.0024364233016967774 second for 10 tests\n"
     ]
    }
   ],
   "source": [
    "verifying_test(L, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 1000\n",
    "issue_time = []\n",
    "parameter_time = []\n",
    "verify_time = []\n",
    "identify = ['Average Time']\n",
    "identify.extend(['#'+str(x) for x in range(1,times + 1)])\n",
    "issue_test(L, times, issue_time, 0)\n",
    "parameter_test(L, times, parameter_time, 0)\n",
    "verifying_test(L, times, verify_time, 0)\n",
    "avg1 = sum(issue_time)/times\n",
    "avg2 = sum(parameter_time)/times\n",
    "avg3 = sum(verify_time)/times\n",
    "issue_time.insert(0, avg1)\n",
    "parameter_time.insert(0, avg2)\n",
    "verify_time.insert(0, avg3)\n",
    "dataframe = pd.DataFrame({'Rounds [TEST DATE: ' + time.strftime('%Y-%m-%d %H:%M',time.localtime(time.time())) + ']':identify, 'Issuing Time':issue_time, 'Parameter Time': parameter_time, 'Verifying Time': verify_time})\n",
    "dataframe.to_csv('./ECC_256_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
